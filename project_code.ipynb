{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e421c93-d541-4057-8ce9-e4c7f217e6c2",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d68c36-2a44-4db3-b720-cf0feeaf3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nfl_data_py as nfl\n",
    "import pandas as pd\n",
    "import re\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments\n",
    "from transformers import Trainer, BertForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset, DatasetDict, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acda352-372e-41da-8258-b3bd9876b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the spread of play type over each year\n",
    "\n",
    "# 2022\n",
    "df_2022 = nfl.import_pbp_data([2022], downcast=True, cache=False, alt_path=None)\n",
    "\n",
    "print(len(df_2022))\n",
    "print(df_2022['play_type'].value_counts())\n",
    "\n",
    "# 2023\n",
    "df_2023 = nfl.import_pbp_data([2023], downcast=True, cache=False, alt_path=None)\n",
    "\n",
    "print(len(df_2023))\n",
    "print(df_2023['play_type'].value_counts())\n",
    "\n",
    "# 2024\n",
    "df_2024 = nfl.import_pbp_data([2024], downcast=True, cache=False, alt_path=None)\n",
    "\n",
    "print(len(df_2024))\n",
    "print(df_2024['play_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657acb1-1c11-49ba-bf78-fc419faf1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the most recent 3 seasons\n",
    "years_wanted = [2022, 2023, 2024]\n",
    "\n",
    "# Get the data from the nfl library - this is described in their python docs\n",
    "df = nfl.import_pbp_data(years_wanted, downcast=True, cache=False, alt_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e0469-2cbc-40f6-a0ea-a46da91953f5",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73fc4e9-4027-4883-af7b-061fc6079eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose valid play types\n",
    "valid_play_types = ['run', 'pass']\n",
    "mask = df['play_type'].isin(valid_play_types)\n",
    "df = df[mask]\n",
    "\n",
    "# Choose the feature columns needed to construct the text for the play_type\n",
    "selected_columns = ['posteam', 'defteam', 'qtr', 'down', 'play_type', 'ydstogo', 'yardline_100', \n",
    "                   'offense_personnel', 'defense_personnel', 'passer_player_name', \n",
    "                    'quarter_seconds_remaining', 'no_huddle', 'shotgun', 'desc', 'first_down', \n",
    "                   'touchdown', 'yards_gained', 'fumble_lost', 'interception', 'incomplete_pass']\n",
    "\n",
    "df['passer_player_name'] = df['passer_player_name'].fillna('The QB')\n",
    "df = df.dropna(subset=selected_columns)\n",
    "df = df[selected_columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb4e9a-7e9d-4e50-abbf-3519a69c5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to generate input_text\n",
    "def generate_input_text(row):\n",
    "    # Get the feature columns for the current row\n",
    "    offense = row['posteam']\n",
    "    defense = row['defteam']\n",
    "    qb = row['passer_player_name']\n",
    "    off_look = row['offense_personnel']\n",
    "    def_look = row['defense_personnel']\n",
    "    qtr = row['qtr']\n",
    "    down = int(row['down'])\n",
    "    play = row['play_type']\n",
    "    ydstogo = int(row['ydstogo'])\n",
    "    disttd = int(row['yardline_100'])\n",
    "    qtr_left = row['quarter_seconds_remaining']\n",
    "    no_hud = row['no_huddle']\n",
    "    sg = row['shotgun']\n",
    "\n",
    "    ## Redefine the time left in the quarter to a string that\n",
    "    ## converts to minutes because 500+ seconds is not how\n",
    "    ## a person would describe it\n",
    "    # Check if there is minutes or seconds left\n",
    "    if qtr_left > 60:\n",
    "        # Round to the current number of minutes left\n",
    "        min = int(qtr_left / 60)\n",
    "        \n",
    "        # Check if its only one minute, so that there is no s\n",
    "        if min > 1:\n",
    "            qtr_left = f\"{min} minutes\"\n",
    "        else:\n",
    "            qtr_left = f\"{min} minute\"\n",
    "\n",
    "    # If there is less than a minute left, check if its only one second, so that there is no s\n",
    "    else:\n",
    "        if qtr_left > 1.0:\n",
    "            qtr_left = f\"{int(qtr_left)} seconds\"\n",
    "        else:\n",
    "            qtr_left = f\"{int(qtr_left)} second\"\n",
    "\n",
    "    ## Redefine quarter so it is a string and uses the\n",
    "    ## conventional first second third\n",
    "    if qtr == 1.0:\n",
    "        qtr = f\"{int(qtr)}st\"\n",
    "    elif qtr == 2.0:\n",
    "        qtr = f\"{int(qtr)}nd\"\n",
    "    elif qtr == 3.0:\n",
    "        qtr = f\"{int(qtr)}rd\"\n",
    "    elif qtr == 4.0:\n",
    "        qtr = f\"{int(qtr)}th\"\n",
    "\n",
    "    ## Redefine down so it is a string and uses the\n",
    "    ## conventional firt second third\n",
    "    if down == 1:\n",
    "        down = f\"{down}st\"\n",
    "    elif down == 2:\n",
    "        down = f\"{down}nd\"\n",
    "    elif down == 3:\n",
    "        down = f\"{down}rd\"\n",
    "    elif down == 4:\n",
    "        down = f\"{down}th\"\n",
    "        \n",
    "    ## Convert the current distance to the goaline based on \n",
    "    ## what side of the 50 the offense is on\n",
    "    if disttd > 50:\n",
    "        disttd = f\"{defense}'s {disttd} yardline\"\n",
    "    elif disttd < 50:\n",
    "        disttd = f\"their own {disttd} yardline\"\n",
    "    elif disttd == 50:\n",
    "        disttd = f\"the 50 yardline\"\n",
    "\n",
    "    ## Define natural language options for if the offense is in shotgun formation\n",
    "    shotgun_options = [\"Shotgun formation.\", f\"{qb} is in shotgun.\", \"The offense has shotgun formation.\", \n",
    "                       \"Offense in shotgun.\", \"The QB is in shotgun.\", \"Shotgun snap.\", \n",
    "                       \"The quarterback is in shotgun formation.\", \"Shotgun formation for the QB.\", \n",
    "                       \"And the QB is in shotgun.\", \"The offense went with the QB in shotgun.\", \n",
    "                       f\"{offense} had the QB in shotgun.\", f\"{offense} put the quarterback in shotgun.\", \n",
    "                       f\"{qb} in shotgun formation.\", f\"Shotgun for {offense}.\", f\"Back in shotgun is {qb}.\", \n",
    "                      \"Shotgun.\", f\"{qb} as QB in shotgun.\", \"The quarterback in shotgun.\"]\n",
    "\n",
    "    ## Define natural language options for if the offense is going no huddle\n",
    "    no_hud_options = [\"The offense went no huddle.\", \"No huddle.\", \"No huddle play.\", \"No huddle offense.\", \n",
    "                     f\"{offense} went no huddle.\", f\"{offense} offense didn't huddle.\", \"No huddle needed for the offense\", \n",
    "                     f\"No huddle needed for {offense}.\", f\"And {qb} did not huddle the offense.\", \"Huddle was not needed.\", \n",
    "                     f\"Huddle wasn't needed for the {offense} team\", \"Huddle unnecessary for the offense.\", \"Play with no huddle\", \n",
    "                     f\"Still no huddle is {offense}.\", \"Play needed no huddle.\", \"The offense went with no huddle\", \n",
    "                     \"No huddle necessary for the offense.\"]\n",
    "\n",
    "    ## Define the main body of templates for the input text,\n",
    "    ## this uses the remaining features given for input\n",
    "    ## There is around 100 options given here\n",
    "    main_options = [ f\"With about {qtr_left} remaining in the {qtr} quarter, {offense} lines up for a {play} on {down} and {ydstogo} from {disttd}. {qb} leads the offense, which is showing {off_look}, while the defense from {defense} sets up in {def_look}.\", \n",
    "                    f\"{offense} faces {down} and {ydstogo} from {disttd} with {qtr_left} to go in the {qtr} quarter. The offensive formation is {off_look}, with {qb} at quarterback. {defense} shows a {def_look} defensive look.\", \n",
    "                    f\"Early in the {qtr} quarter with {qtr_left} remaining, {offense} is preparing a {play} from {disttd}. It's {down} down and {ydstogo} to go. Offensive look: {off_look}. Defensive setup by {defense}: {def_look}.\", \n",
    "                    f\"{offense} sets up on {down} and {ydstogo}, positioned at {disttd}. The clock shows {qtr_left} in the {qtr} quarter. {qb} is in command, working behind a {off_look} formation. {defense} counters with {def_look}.\", \n",
    "                    f\"Clock winding down in the {qtr} quarter — {qtr_left} left. {offense} is lined up on {down} and {ydstogo} at {disttd}. The offense shows {off_look}, and {qb} gets ready to lead the {play}. {defense} is lined up in {def_look}.\", \n",
    "                    f\"Midway through the {qtr} quarter ({qtr_left} left), {offense} has the ball on {down} and {ydstogo} from {disttd}. {qb} prepares to execute a {play}. Formation: {off_look} vs. {defense}'s {def_look}.\", \n",
    "                    f\"In the {qtr} quarter with {qtr_left} left on the clock, {offense} is set up on {down} and {ydstogo} at {disttd}. {qb} is behind a {off_look} offensive formation, while the defense from {defense} lines up in {def_look}.\", \n",
    "                    f\"{offense} looks to convert on {down} and {ydstogo} with {qtr_left} to go in the {qtr}. They’re on {disttd}, running a {play} play with {qb} at the helm and {off_look} personnel. {defense} is showing {def_look}.\", \n",
    "                    f\"{down} and {ydstogo}, {offense} has possession at {disttd}. There's {qtr_left} left in the {qtr} quarter. {qb} leads the offense in a {off_look} look. The defense, {defense}, presents a {def_look} formation.\", \n",
    "                    f\"{offense} lines up for a {play} play on {down} and {ydstogo} from {disttd}. Time remaining in the {qtr} quarter: {qtr_left}. {off_look} is the offensive look, led by {qb}. The defense ({defense}) sets up with {def_look}.\", \n",
    "                    f\"In the {qtr} quarter with about {qtr_left} left, {offense} prepares a {play} on {down} and {ydstogo}. Ball is on {disttd}. {qb} heads the offense in {off_look}, facing {defense}'s {def_look}.\", \n",
    "                    f\"{qb} is at quarterback as {offense} prepares a {play} from {disttd}. It's {down} and {ydstogo} in the {qtr} quarter with {qtr_left} on the clock. The offense lines up in {off_look} against {defense}'s {def_look}.\", \n",
    "                    f\"With about {qtr_left} left in the {qtr} quarter, {offense} is {down} and {ydstogo} from {disttd}. The offense has {off_look} on the field, while {defense} has {def_look} on the field. {qb} is looking to run a {play}\", \n",
    "                    f\"With {qtr_left} left in the {qtr}, it's {down} and {ydstogo} for {offense} at {disttd}. {qb} leads the offense with {off_look} on the field, facing a {def_look} look from {defense}. They're lining up for a {play}.\", \n",
    "                    f\"The {qtr} quarter continues with {offense} on {down} and {ydstogo} from {disttd}. {qtr_left} on the clock. {qb} commands a {off_look} formation against {defense}'s {def_look}, preparing for a {play} play.\", \n",
    "                    f\"{offense} takes the snap on {down} and {ydstogo}, located at {disttd}. {qtr_left} remains in the {qtr}. {qb} is under center, flanked by {off_look}. The {defense} defense sets up in a {def_look} front for the upcoming {play}.\", \n",
    "                    f\"{qtr_left} left in the {qtr} quarter, and {offense} looks to gain {ydstogo} yards from {disttd}. It's {down} down. {qb} gets ready to execute a {play} behind a {off_look} formation, while {defense} prepares in {def_look}.\", \n",
    "                    f\"Approaching crunch time in the {qtr} quarter — {qtr_left} left. {offense} sets up for a {play} on {down} and {ydstogo} from {disttd}. {qb} is under center with {off_look} personnel. {defense} responds with {def_look}.\", \n",
    "                    f\"{offense} starts the play on {down} and {ydstogo} at {disttd}, with {qtr_left} left in the {qtr}. The offense is showing {off_look}, and {qb} prepares for a {play}. {defense} sets up in {def_look}.\",\n",
    "                    f\"The ball is placed at {disttd} as {offense} faces {down} and {ydstogo}. {qtr_left} remains in the {qtr} quarter. The offensive unit led by {qb} shows {off_look}; {defense} counters with {def_look}.\",\n",
    "                    f\"{offense} is ready for a {play} from {disttd}. It's {down} down and {ydstogo} with {qtr_left} left in the {qtr}. Formation: {off_look}. {qb} leads the offense. Defense ({defense}) lines up in {def_look}.\",\n",
    "                    f\"From {disttd}, {offense} is on {down} and {ydstogo}. The time reads {qtr_left} in the {qtr}. {qb} prepares for a {play} behind {off_look}. {defense} positions with a {def_look} scheme.\",\n",
    "                    f\"{offense} aligns in a {off_look} setup for {down} and {ydstogo} from {disttd}. {qtr_left} left in the {qtr}. {qb} signals the {play} while {defense} readies in {def_look}.\",\n",
    "                    f\"In the {qtr}, {offense} has the ball on {down} and {ydstogo} at {disttd}. {qb} looks over a {off_look} formation. Defense by {defense} shows {def_look}. Time left: {qtr_left}.\",\n",
    "                    f\"{qb} is set to lead a {play} for {offense} from {disttd}, facing {down} and {ydstogo}. It's the {qtr} quarter, {qtr_left} to go. Defense from {defense} sets up in {def_look}.\",\n",
    "                    f\"{down} down and {ydstogo} for {offense}, the ball rests at {disttd}. {qb} scans the defense from a {off_look} set. Clock reads {qtr_left} in the {qtr}. Defense shows {def_look}.\",\n",
    "                    f\"Just {qtr_left} on the clock in the {qtr}. {offense} lines up for {down} and {ydstogo} from {disttd}. The formation is {off_look} with {qb} calling the {play}. {defense} lines up in {def_look}.\",\n",
    "                    f\"At {disttd}, {offense} preps for a {play}. It's {down} down and {ydstogo} with {qtr_left} in the {qtr}. {qb} takes charge behind {off_look}. {defense} is in {def_look}.\",\n",
    "                    f\"{offense} gets ready for {down} and {ydstogo} from {disttd}. {qb} barks out signals from the {off_look} look. {defense} sets in a {def_look} stance. {qtr} quarter, {qtr_left} remaining.\",\n",
    "                    f\"In the {qtr}, {offense} is on {down} and {ydstogo} at {disttd}. Formation: {off_look}. {qb} at the helm. The defense ({defense}) counters with {def_look}. {qtr_left} on the clock.\",\n",
    "                    f\"{offense} comes out in {off_look} for a {play} from {disttd}. It's {down} and {ydstogo}, and the {qtr} quarter is winding down with {qtr_left} left. {defense} lines up in {def_look}.\",\n",
    "                    f\"At {disttd}, it's {down} and {ydstogo} for {offense}. {qb} lines up behind {off_look}. {qtr_left} left in the {qtr}. The defense by {defense} is set in {def_look}.\",\n",
    "                    f\"{qb} leads {offense} into a {play} attempt from {disttd}, facing {down} and {ydstogo}. {qtr} quarter, {qtr_left} left. Defense shows {def_look} against a {off_look} formation.\",\n",
    "                    f\"Ball on {disttd}, {down} and {ydstogo} for {offense}. The offense shows {off_look}. Clock reads {qtr_left} in the {qtr}. {qb} ready to run the {play} against {def_look}.\",\n",
    "                    f\"Midway in the {qtr}, {offense} lines up for {down} and {ydstogo} from {disttd}. {off_look} is the look, with {qb} ready. Defense from {defense} counters in {def_look}.\",\n",
    "                    f\"{offense} preps for a key {play} on {down} and {ydstogo} at {disttd}. The {qtr} quarter shows {qtr_left} remaining. {qb} under center. {defense} shows a {def_look}.\",\n",
    "                    f\"{offense} is at the line on {down} and {ydstogo}, ball at {disttd}. {qb} is in {off_look} formation. {qtr_left} remains in the {qtr}. {defense} shows {def_look}.\",\n",
    "                    f\"From {disttd}, {offense} is set up for {down} and {ydstogo}. {qb} stands tall behind a {off_look} look. {defense} adjusts into {def_look}. {qtr_left} left in the {qtr}.\",\n",
    "                    f\"It's {down} and {ydstogo}, {offense} lines up on {disttd}. {qb} prepares to run a {play}. Offensive look is {off_look}. {defense} counters in {def_look}. {qtr_left} on the clock.\",\n",
    "                    f\"{qb} in command for {offense} on {down} and {ydstogo}. {off_look} is the setup from {disttd}. {defense} forms in {def_look}. The {qtr} quarter has {qtr_left} left.\",\n",
    "                    f\"{offense} breaks the huddle with {qb} under center for {down} and {ydstogo}. They're at {disttd}, lined up in {off_look}. The defense ({defense}) uses a {def_look} set. {qtr_left} to go.\",\n",
    "                    f\"With {qtr_left} left in the {qtr}, {offense} takes the field at {disttd} for a {play}. It's {down} down and {ydstogo}. Formation: {off_look}. Defense responds with {def_look}.\",\n",
    "                    f\"{offense} on offense, ball spotted at {disttd}. {down} and {ydstogo}. Formation: {off_look}. {qb} behind center. {defense} showing {def_look}. {qtr_left} remains in the {qtr}.\",\n",
    "                    f\"From {disttd}, {qb} prepares for {down} and {ydstogo}. It's the {qtr} quarter, with {qtr_left} left. The offense ({offense}) lines up in {off_look}, {defense} matches with {def_look}.\",\n",
    "                    f\"The {qtr} continues as {offense} lines up at {disttd} for {down} and {ydstogo}. {qb} ready in a {off_look} formation. Defense by {defense} shows {def_look}. {qtr_left} to play.\",\n",
    "                    f\"Just {qtr_left} to go in the {qtr}. {offense} has {down} and {ydstogo} from {disttd}. {qb} in {off_look}. {defense} defense readies with {def_look}.\",\n",
    "                    f\"Snap coming soon: {offense} has {down} and {ydstogo} from {disttd}. {qtr_left} left in the {qtr}. Formation: {off_look}. {qb} calling signals. {defense} in {def_look}.\", \n",
    "                    f\"{qb} prepares for a {play} as {offense} faces {down} and {ydstogo} from {disttd}. It’s the {qtr} with {qtr_left} left. Formation: {off_look}. Defense: {def_look} by {defense}.\",\n",
    "                    f\"The play clock winds down as {offense} gets into position for {down} and {ydstogo} from {disttd}. {qb} directs from a {off_look} formation. {defense} counters with {def_look}.\",\n",
    "                    f\"On {down} and {ydstogo}, {offense} takes the snap at {disttd}. It’s late in the {qtr} with {qtr_left} left. {qb} in a {off_look} look. Defense lines up in {def_look}.\",\n",
    "                    f\"{offense} positions at {disttd} for a {play}. It's {down} and {ydstogo}, {qtr_left} to go in the {qtr}. {qb} behind {off_look}, facing {defense} in {def_look}.\",\n",
    "                    f\"{qb} leads {offense} on a {play} attempt from {disttd}. They face {down} and {ydstogo}. {off_look} is the look. {qtr} quarter, {qtr_left} left. {defense} sets up with {def_look}.\",\n",
    "                    f\"{down} and {ydstogo} at {disttd} for {offense}. {qb} barks out signals from the {off_look} formation. {qtr_left} in the {qtr}. Defense by {defense} is set in {def_look}.\",\n",
    "                    f\"{offense} is at {disttd}, running a {play} on {down} and {ydstogo}. It’s the {qtr} with {qtr_left} left. {qb} in a {off_look} formation. {defense} showing {def_look}.\",\n",
    "                    f\"{qb} sets up for {offense} on {down} and {ydstogo} from {disttd}. With {qtr_left} in the {qtr}, the formation is {off_look}. {defense} shows a {def_look} front.\",\n",
    "                    f\"Time ticking in the {qtr}, {qtr_left} left. {offense} sets up for {down} and {ydstogo} from {disttd}. {qb} commands from a {off_look} look. {defense} counters with {def_look}.\",\n",
    "                    f\"{offense} comes out in {off_look} for {down} and {ydstogo} at {disttd}. {qb} under center. The defense ({defense}) shows {def_look}. Time left: {qtr_left} in the {qtr}.\",\n",
    "                    f\"It’s {down} down and {ydstogo} for {offense}, who line up at {disttd}. {qtr_left} remains in the {qtr}. {qb} leads from a {off_look} setup. {defense} lines up in {def_look}.\",\n",
    "                    f\"{qb} prepares to snap for {offense} on {down} and {ydstogo} from {disttd}. {qtr_left} remains in the {qtr}. Formation: {off_look}. {defense} shows a {def_look} alignment.\",\n",
    "                    f\"{offense} sets for a {play} on {down} and {ydstogo} from {disttd}. In the {qtr} with {qtr_left} remaining, {qb} lines up behind a {off_look} formation. Defense: {def_look}.\",\n",
    "                    f\"The ball is at {disttd}, and {offense} is looking at {down} and {ydstogo}. {qb} prepares for a {play}. {off_look} is the formation. {qtr} quarter, {qtr_left} left. Defense: {def_look}.\",\n",
    "                    f\"{qb} gets the offense ready at {disttd} for {down} and {ydstogo}. With {qtr_left} left in the {qtr}, they show {off_look}. The {defense} defense readies in {def_look}.\",\n",
    "                    f\"{offense} breaks the huddle and lines up at {disttd} for {down} and {ydstogo}. {qb} stands in {off_look}. The clock shows {qtr_left} in the {qtr}. Defense: {def_look}.\",\n",
    "                    f\"{offense} sets up for a big play: {down} and {ydstogo} at {disttd}. {qtr_left} left in the {qtr}. Formation is {off_look} with {qb} calling signals. {defense} is in {def_look}.\",\n",
    "                    f\"{qb} has {offense} lined up at {disttd}. It’s {down} and {ydstogo} with {qtr_left} left in the {qtr}. The offense shows {off_look}. {defense} prepares with {def_look}.\",\n",
    "                    f\"The {qtr} quarter continues with {offense} on {down} and {ydstogo} at {disttd}. {qb} surveys the defense from a {off_look} formation. {defense} is in {def_look}. Time: {qtr_left}.\",\n",
    "                    f\"{offense} gets into position at {disttd} for a {play}. It’s {down} and {ydstogo} in the {qtr} with {qtr_left} left. Formation: {off_look}. Defense: {def_look}. {qb} leads the charge.\",\n",
    "                    f\"{qb} takes the field for {offense} on {down} and {ydstogo} from {disttd}. {qtr_left} in the {qtr}. Formation: {off_look}. {defense} prepares in {def_look}.\",\n",
    "                    f\"With {qtr_left} left in the {qtr}, it’s {down} and {ydstogo} for {offense} from {disttd}. {qb} is ready behind a {off_look} look. {defense} matches up in {def_look}.\",\n",
    "                    f\"Ball at {disttd}, it’s {down} and {ydstogo} for {offense}. {qb} in command from the {off_look} formation. {defense} shows a {def_look} front. {qtr} quarter, {qtr_left} left.\",\n",
    "                    f\"{qb} preps a {play} for {offense}, positioned on {down} and {ydstogo} at {disttd}. Formation is {off_look}. Time remaining in {qtr}: {qtr_left}. {defense} set in {def_look}.\",\n",
    "                    f\"The {qtr} quarter ticks on with {qtr_left} remaining. {offense} has {down} and {ydstogo} from {disttd}. {qb} leads from {off_look}. {defense} sets up with {def_look}.\",\n",
    "                    f\"With {qtr_left} left, {offense} prepares for a {play} from {disttd}. It’s {down} and {ydstogo}. {qb} stands behind a {off_look} formation. Defense by {defense} shows {def_look}.\",\n",
    "                    f\"{offense} is lined up on {down} and {ydstogo} from {disttd}. It’s the {qtr} quarter with {qtr_left} left. {qb} in {off_look}. {defense} counters with {def_look}.\",\n",
    "                    f\"{down} and {ydstogo}, {offense} is ready at {disttd}. {qb} preps a {play} behind {off_look}. {qtr_left} remains in the {qtr}. Defense: {def_look} from {defense}.\",\n",
    "                    f\"At {disttd}, {offense} gets ready for {down} and {ydstogo}. {qb} commands from {off_look}. {qtr_left} on the clock. {defense} shows a {def_look}.\",\n",
    "                    f\"In the {qtr} quarter with {qtr_left} left, {offense} is positioned for a {play}. It’s {down} and {ydstogo} at {disttd}. Formation: {off_look}. Defense: {def_look}.\",\n",
    "                    f\"{qb} leads {offense} on {down} and {ydstogo}, setting up at {disttd}. {off_look} is the formation. {qtr_left} left in the {qtr}. Defense by {defense} is showing {def_look}.\",\n",
    "                    f\"{offense} takes the field on {down} and {ydstogo}. Ball on {disttd}. {qb} aligns the team in {off_look}. {defense} sets up in {def_look}. Time remaining: {qtr_left} of the {qtr}.\", \n",
    "                    f\"{qb} commands the huddle as {offense} lines up for {down} and {ydstogo} from {disttd}. {qtr_left} remains in the {qtr}. Formation: {off_look}, Defense: {def_look}.\",\n",
    "                    f\"Play clock winding down in the {qtr}, {qtr_left} to go. {offense} at {disttd} for {down} and {ydstogo}. {qb} sets in {off_look}. Defense: {def_look}.\",\n",
    "                    f\"{offense} lines up in {off_look} for a {play} from {disttd}. It’s {down} and {ydstogo}. {qb} faces off against {defense} in a {def_look} defense. Time left: {qtr_left}.\",\n",
    "                    f\"{down} and {ydstogo} coming up for {offense}, stationed at {disttd}. {qb} surveys the field from a {off_look} look. It’s the {qtr} with {qtr_left} remaining. {defense} shows {def_look}.\",\n",
    "                    f\"{qb} leads {offense} out for a critical {play}. Ball on {disttd}, {down} and {ydstogo}. Formation: {off_look}. {qtr_left} in the {qtr}. {defense} shows {def_look}.\",\n",
    "                    f\"In the {qtr} quarter with {qtr_left} remaining, {offense} has {down} and {ydstogo} at {disttd}. {qb} steps into a {off_look} formation. {defense} prepares in {def_look}.\",\n",
    "                    f\"Late in the {qtr}, {qtr_left} remaining. {offense} faces {down} and {ydstogo} from {disttd}. {qb} sets the offense in {off_look}. {defense} counters with {def_look}.\",\n",
    "                    f\"{qb} has {offense} aligned for a {play} at {disttd}, facing {down} and {ydstogo}. Time in the {qtr}: {qtr_left}. Formation: {off_look}. {defense} lines up in {def_look}.\",\n",
    "                    f\"Crunch time in the {qtr}, {qtr_left} on the clock. {offense} with {down} and {ydstogo} from {disttd}. {qb} leads in {off_look}. {defense} answers in {def_look}.\",\n",
    "                    f\"{offense} gets in formation at {disttd}. {down} and {ydstogo}, and the clock reads {qtr_left} in the {qtr}. {qb} stands tall behind the {off_look}. {defense}: {def_look}.\",\n",
    "                    f\"{qb} and {offense} are ready for a {play}. Ball spotted at {disttd}, it's {down} and {ydstogo}. {qtr_left} to go in the {qtr}. Defense: {def_look} from {defense}.\",\n",
    "                    f\"It’s {down} and {ydstogo} at {disttd}, and {offense} is in {off_look}. {qb} eyes the {defense} defense showing {def_look}. {qtr_left} left in the {qtr}.\",\n",
    "                    f\"{qb} takes command as {offense} readies for a {play}. They’re facing {down} and {ydstogo} from {disttd}. Clock shows {qtr_left} in the {qtr}. {defense} shows {def_look}.\",\n",
    "                    f\"Time: {qtr_left} left in the {qtr}. {offense} faces {down} and {ydstogo} at {disttd}. {qb} is under center in {off_look}. {defense} shows {def_look}.\",\n",
    "                    f\"{offense} comes to the line on {down} and {ydstogo} from {disttd}. {qb} preps a {play} from the {off_look} look. {qtr_left} in the {qtr}. Defense: {def_look}.\",\n",
    "                    f\"{qb} and the offense break huddle for {down} and {ydstogo}. Ball at {disttd}. Time: {qtr_left} in the {qtr}. Formation: {off_look}, Defense: {def_look}.\",\n",
    "                    f\"Approaching the end of the {qtr}, {qtr_left} left. {offense} at {disttd} with {down} and {ydstogo}. {qb} directs traffic from the {off_look}. {defense}: {def_look}.\",\n",
    "                    f\"{qb} leads a {play} from the {off_look} look. {offense} faces {down} and {ydstogo} at {disttd}, {qtr_left} to go in the {qtr}. {defense} prepares in {def_look}.\"]\n",
    "\n",
    "    # Choose the random main body for the input text\n",
    "    input = random.choice(main_options)\n",
    "\n",
    "    # Check if the offense was in shotgun formation and append a random option to the body of the input text if so\n",
    "    if sg == 1.0:\n",
    "        input += \" \" + random.choice(shotgun_options)\n",
    "\n",
    "    # Check if the offense went no huddle and append a random option to the body of the input text if so\n",
    "    if no_hud == 1.0:\n",
    "        input += \" \" + random.choice(no_hud_options)\n",
    "\n",
    "    return input\n",
    "\n",
    "\n",
    "## Function to generate target_text and outcome_label\n",
    "def generate_output_text(row):\n",
    "    #### For T5 output\n",
    "\n",
    "    ## Get the features needed from the current row\n",
    "    desc = row['desc']\n",
    "    qb = row['passer_player_name']\n",
    "\n",
    "    # Define the regex to select all of the player names and their numbers\n",
    "    ## This looks like (## - P. Mahomes)\n",
    "    player_name_regex = r\"\\d{1,2}-[A-Z]\\.[A-Za-z]+\"\n",
    "    matches = re.findall(player_name_regex, desc)\n",
    "\n",
    "    # Check each of the player names against the QB\n",
    "    for player in matches:\n",
    "        # Remove the dash and jersey number as these aren't in the\n",
    "        # passer_player_name\n",
    "        player_ops = [player[2:], player[3:], \"The QB\"]\n",
    "\n",
    "        # If the name is not the QBs, then anonymize to a player\n",
    "        if qb not in player_ops:\n",
    "            desc = desc.replace(player, 'a player')\n",
    "\n",
    "    # Define regex to select all of the variations of parentesis\n",
    "    # In the play by play this is the game clock so removing this gets \n",
    "    # rid of the problem of the model guessing those numbers\n",
    "    parenthesis_regex = r\"\\([^)]*\\)\"\n",
    "    matches = re.findall(parenthesis_regex, desc)\n",
    "\n",
    "    # Remove all the parenthesis instances\n",
    "    for parenthesis in matches:\n",
    "        desc = desc.replace(parenthesis, \"\")\n",
    "        \n",
    "    #### For BERT Output\n",
    "\n",
    "    # Get all of the features needed for the current row\n",
    "    fd = row['first_down']\n",
    "    td = row['touchdown']\n",
    "    yds = row['yards_gained']\n",
    "    ydstogo = row['ydstogo']\n",
    "    fumble = row['fumble_lost']\n",
    "    interception = row['interception']\n",
    "    down = int(row['down'])\n",
    "    ic = row['incomplete_pass']\n",
    "\n",
    "    label = None\n",
    "\n",
    "    # Assign the labels mutually exclusively, this is defined\n",
    "    # in more detail in the report\n",
    "    if td == 1.0:\n",
    "        label = 'touchdown'\n",
    "    elif fd == 1.0:\n",
    "        label = 'first_down'\n",
    "    elif fumble == 1.0 or interception == 1.0:\n",
    "        label = 'turnover'\n",
    "    elif down == 3 and fd != 1.0:\n",
    "        label = 'failed_third_down_conversion'\n",
    "    elif ic == 1.0:\n",
    "        label = 'incomplete_pass'\n",
    "    elif yds < 0:\n",
    "        label = 'yardage_lost'\n",
    "    elif yds == 0:\n",
    "        label = 'no_gain'\n",
    "    elif yds > 0:\n",
    "        label = 'yardage_gained'\n",
    "    else:\n",
    "        label = 'no_label'\n",
    "        \n",
    "\n",
    "    return desc, label\n",
    "    \n",
    "\n",
    " \n",
    "# Define a function to convert each rows data inputs and outputs to text for the model\n",
    "def format_as_nl(row):\n",
    "    input = generate_input_text(row)\n",
    "    output_t5, output_bert = generate_output_text(row)\n",
    "\n",
    "    return {\"input_text\": input,\n",
    "           \"target_text\": output_t5,\n",
    "           \"outcome_label\": output_bert}\n",
    "    \n",
    "# Apply the constructed functions to the data and convert to a df\n",
    "final_data = df.apply(format_as_nl, axis=1).tolist()\n",
    "final_data = pd.DataFrame(final_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73537c8a-5092-4395-8bc2-f70c4572898a",
   "metadata": {},
   "source": [
    "## Splitting the Data for the Two Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d3f7a-b749-4142-bdea-788475dd8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "df_shuffled = final_data.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "## Split the data based on the two models, so 50/50\n",
    "split = int(len(df_shuffled) * 0.5)\n",
    "\n",
    "t5_data = df_shuffled[:split].reset_index(drop=True)\n",
    "bert_data = df_shuffled[split:].reset_index(drop=True)\n",
    "\n",
    "## Split the t5 data for train/val/test as 80/10/10\n",
    "train = int(len(t5_data) * 0.8)\n",
    "val = train + int(len(t5_data) * 0.1)\n",
    "\n",
    "t5_train = t5_data[:train].reset_index(drop=True)\n",
    "t5_val = t5_data[train:val].reset_index(drop=True)\n",
    "t5_test = t5_data[val:].reset_index(drop=True)\n",
    "\n",
    "print(len(t5_data), len(t5_train), len(t5_val), len(t5_test))\n",
    "\n",
    "## Split the BERT data for train/val/test1/test2 as 80/10/5/5\n",
    "train = int(len(bert_data) * 0.8)\n",
    "val = train + int(len(bert_data) * 0.1)\n",
    "test1 = val + int(len(bert_data) * 0.05)\n",
    "\n",
    "bert_train = bert_data[:train].reset_index(drop=True)\n",
    "bert_val = bert_data[train:val].reset_index(drop=True)\n",
    "bert_test1 = bert_data[val:test1].reset_index(drop=True)\n",
    "bert_test2 = bert_data[test1:].reset_index(drop=True)\n",
    "\n",
    "print(len(bert_data), len(bert_train), len(bert_val), len(bert_test1), len(bert_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee04fe-aafb-45a2-bd06-619dc8bcd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data['outcome_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc3160-b4f8-4188-ae91-b67c96dea106",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(bert_data['input_text'][i])\n",
    "    print(bert_data['target_text'][i])\n",
    "    print(bert_data['outcome_label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada089a1-0c27-4b67-b687-5896add1aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(t5_data['input_text'][i])\n",
    "    print(t5_data['target_text'][i])\n",
    "    print(t5_data['outcome_label'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0355fcc-df60-43b2-ac7d-37bfe823ec1e",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f576a7-1e34-46a4-9a87-b5263ae1fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting baselines for the BERT model\n",
    "\n",
    "## Baseline One: Using random class label\n",
    "class_labels = ['touchdown', 'first_down', 'turnover', 'failed_third_down_conversion', 'incomplete_pass', \n",
    "               'yardage_lost', 'no_gain', 'yardage_gained']\n",
    "\n",
    "num_y = len(bert_test1)\n",
    "\n",
    "random.seed(123)\n",
    "baseline_one_bert = random.choices(class_labels, k = num_y)\n",
    "\n",
    "true_y = list(bert_test1['outcome_label'])\n",
    "\n",
    "print(\"Baseline One Accuracy:\", accuracy_score(true_y, baseline_one_bert))\n",
    "print(\"Baseline One F1:\", f1_score(true_y, baseline_one_bert, average = 'macro'))\n",
    "\n",
    "## Baseline Two: Using majority class label\n",
    "baseline_two_bert = ['yardage_gained'] * num_y\n",
    "\n",
    "print(\"Baseline Two Accuracy:\", accuracy_score(true_y, baseline_two_bert))\n",
    "print(\"Baseline Two F1:\", f1_score(true_y, baseline_two_bert, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2582a-dbaf-437a-8fad-3d4fad7c2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting baselines for the T5 model\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "## Baseline One: shuffling the target text for the input_text\n",
    "baseline_one_t5 = list(t5_test[\"target_text\"])\n",
    "random.seed(123)\n",
    "random.shuffle(baseline_one_t5)\n",
    "\n",
    "true_y = list(t5_test['target_text'])\n",
    "\n",
    "bleu_score = bleu.compute(predictions = baseline_one_t5, references = [[y] for y in true_y])\n",
    "rouge_scores = rouge.compute(predictions = baseline_one_t5, references = true_y)\n",
    "\n",
    "print(\"Baseline One BLEU:\", bleu_score['bleu'])\n",
    "print('Baseline One Rouge One:', rouge_scores['rouge1'])\n",
    "print('Baseline One Rouge Two:', rouge_scores['rouge2'])\n",
    "print('Baseline One Rouge L:', rouge_scores['rougeL'])\n",
    "\n",
    "\n",
    "## Baseline TwoL templated target text based on outcome\n",
    "def template_maker(row):\n",
    "    outcome = row['outcome_label']\n",
    "    \n",
    "    if outcome == 'touchdown':\n",
    "        output = \"The offense got a touchdown.\"\n",
    "    elif outcome == 'first_down':\n",
    "        output = \"The offense got a first down.\"\n",
    "    elif outcome == 'no_gain':\n",
    "        output = \"There was no gain on the play.\"\n",
    "    elif outcome == 'failed_third_down_conversion':\n",
    "        output = \"The offense failed on third down.\"\n",
    "    elif outcome == 'yardage_lost':\n",
    "        output = \"The offense lost some yards on the play.\"\n",
    "    elif outcome == 'yardage_gained':\n",
    "        output = \"The offense gained some yards.\"\n",
    "    elif outcome == 'incomplete_pass':\n",
    "        output = \"The pass was incomplete.\"\n",
    "    elif outcome == 'turnover':\n",
    "        output = \"There was a turnover on the play.\"\n",
    "    else:\n",
    "        output = \"The play had an unknown outcome.\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "baseline_two_t5 = [template_maker(row) for _, row in t5_test.iterrows()]\n",
    "\n",
    "bleu_score = bleu.compute(predictions = baseline_two_t5, references = [[y] for y in true_y])\n",
    "rouge_scores = rouge.compute(predictions = baseline_two_t5, references = true_y)\n",
    "\n",
    "print(\"Baseline Two BLEU:\", bleu_score['bleu'])\n",
    "print('Baseline Two Rouge One:', rouge_scores['rouge1'])\n",
    "print('Baseline Two Rouge Two:', rouge_scores['rouge2'])\n",
    "print('Baseline Two Rouge L:', rouge_scores['rougeL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435df6a4-3920-4d2c-a904-af04637c5185",
   "metadata": {},
   "source": [
    "## Tokenize the Data for the T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eccbcab-d29e-491c-8983-93bb2fde71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer using pretrained t5 small\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Convert dfs to datasets since the tokenizer needs them like this\n",
    "t5_train_set = Dataset.from_pandas(t5_train[['input_text', 'target_text']])\n",
    "t5_val_set = Dataset.from_pandas(t5_val[['input_text', 'target_text']])\n",
    "t5_test_set = Dataset.from_pandas(t5_test[['input_text', 'target_text']])\n",
    "\n",
    "# Function to tokenize the data followind ref in report doc \n",
    "def tokenize(data_set):\n",
    "    # Tokenize the input text\n",
    "    input_enc = tokenizer_t5(data_set['input_text'], max_length = 512, padding = 'max_length', truncation = True)\n",
    "\n",
    "    # Tokenize the target text\n",
    "    target_enc = tokenizer_t5(data_set['target_text'], max_length = 128, padding = 'max_length', truncation = True)\n",
    "\n",
    "    # Place these in a dict format\n",
    "    return {'input_ids': input_enc.input_ids, 'attention_mask': input_enc.attention_mask, 'labels': target_enc.input_ids}\n",
    "\n",
    "# Final dataset dict\n",
    "t5_split_dataset = {'train': t5_train_set, 'validation': t5_val_set, 'test': t5_test_set}\n",
    "\n",
    "# Tokenize all splits\n",
    "t5_tokenized_datasets = {split: data_set.map(tokenize, batched = False) for split, data_set in t5_split_dataset.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae9065d-3b42-4050-b70d-9283084098cc",
   "metadata": {},
   "source": [
    "## Tune for T5 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d55bb-9a80-40c2-8b13-a3bdef191245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tuning weight decay larger = 0.01\n",
    "\n",
    "# Load model using the t5 small model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# Establish the training arguments\n",
    "# One epoch since this is tuning hyperparameters\n",
    "training_args = TrainingArguments(output_dir = './t5-wd-0.01', \n",
    "                                  num_train_epochs = 1, \n",
    "                                  per_device_train_batch_size = 16, \n",
    "                                  per_device_eval_batch_size = 16, \n",
    "                                  warmup_steps = 10, \n",
    "                                  weight_decay = 0.01, \n",
    "                                  logging_dir = './logs', \n",
    "                                  logging_steps = 20, \n",
    "                                  save_total_limit = 1, \n",
    "                                  save_strategy = 'epoch', \n",
    "                                  evaluation_strategy = 'epoch', \n",
    "                                  fp16 = False)\n",
    "\n",
    "# Apply the training arguments, following ref in report doc, as well as \n",
    "# similarities to HW3\n",
    "trainer = Trainer(model = model, \n",
    "                  args = training_args, \n",
    "                  train_dataset = t5_tokenized_datasets['train'], \n",
    "                  eval_dataset = t5_tokenized_datasets['validation'])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3dcdc7-eec6-4040-b452-2962be3f7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate for hyperparameter wd = 0.01\n",
    "# Put model to cpu for faster prediction\n",
    "model = model.to('cpu')\n",
    "\n",
    "# Initialize empty list for the predictions and true_y\n",
    "predictions = []\n",
    "true_y = []\n",
    "\n",
    "# Loop through each item in the test dataset\n",
    "## Uses ref from report doc\n",
    "for row in t5_tokenized_datasets['test']:\n",
    "    # Tokenize the input text\n",
    "    input_tokenized = tokenizer_t5(row['input_text'], return_tensors = \"pt\", truncation = True, padding = True).input_ids\n",
    "    \n",
    "    # Generate the models generated text based on the input text\n",
    "    output_tokenized = model.generate(input_tokenized, max_length = 128)[0]\n",
    "\n",
    "    # Decode the generated response to a string\n",
    "    pred = tokenizer_t5.decode(output_tokenized, skip_special_tokens = True)\n",
    "\n",
    "    # Get the corresponding true value for the current row\n",
    "    y = row['target_text']\n",
    "\n",
    "    # Add the generated prediction and true value to the lists\n",
    "    predictions.append(pred)\n",
    "    true_y.append(y)\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "bleu_score = bleu.compute(predictions = predictions, references = [[y] for y in true_y])\n",
    "print(\"BLEU:\", bleu_score['bleu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947335e-cdf7-48ec-b893-afcdeba0f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tuning weight decay smaller = 0.0001\n",
    "\n",
    "# Load model using the t5 small model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# Establish the training arguments\n",
    "# One epoch since this is tuning hyperparameters\n",
    "training_args = TrainingArguments(output_dir = './t5-wd-0.0001', \n",
    "                                  num_train_epochs = 1, \n",
    "                                  per_device_train_batch_size = 16, \n",
    "                                  per_device_eval_batch_size = 16, \n",
    "                                  warmup_steps = 10, \n",
    "                                  weight_decay = 0.0001, \n",
    "                                  logging_dir = './logs', \n",
    "                                  logging_steps = 20, \n",
    "                                  save_total_limit = 1, \n",
    "                                  save_strategy = 'epoch', \n",
    "                                  evaluation_strategy = 'epoch', \n",
    "                                  fp16 = False)\n",
    "\n",
    "# Apply the training arguments, following ref in report doc, as well as \n",
    "# similarities to HW3\n",
    "trainer = Trainer(model = model, \n",
    "                  args = training_args, \n",
    "                  train_dataset = t5_tokenized_datasets['train'], \n",
    "                  eval_dataset = t5_tokenized_datasets['validation'])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b1d41-3735-46a3-bc1d-e82e67fb6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate for hyperparameter wd = 0.0001\n",
    "# Put model to cpu for faster prediction\n",
    "model = model.to('cpu')\n",
    "\n",
    "# Initialize empty list for the predictions and true_y\n",
    "predictions = []\n",
    "true_y = []\n",
    "\n",
    "# Loop through each item in the test dataset\n",
    "## Uses ref from report doc\n",
    "for row in t5_tokenized_datasets['test']:\n",
    "    # Tokenize the input text\n",
    "    input_tokenized = tokenizer_t5(row['input_text'], return_tensors = \"pt\", truncation = True, padding = True).input_ids\n",
    "    \n",
    "    # Generate the models generated text based on the input text\n",
    "    output_tokenized = model.generate(input_tokenized, max_length = 128)[0]\n",
    "\n",
    "    # Decode the generated response to a string\n",
    "    pred = tokenizer_t5.decode(output_tokenized, skip_special_tokens = True)\n",
    "\n",
    "    # Get the corresponding true value for the current row\n",
    "    y = row['target_text']\n",
    "\n",
    "    # Add the generated prediction and true value to the lists\n",
    "    predictions.append(pred)\n",
    "    true_y.append(y)\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "bleu_score = bleu.compute(predictions = predictions, references = [[y] for y in true_y])\n",
    "print(\"BLEU:\", bleu_score['bleu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d9a96-7534-4d9a-b60a-5350da991e8b",
   "metadata": {},
   "source": [
    "## Training Final T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ff9ef-b7fa-4182-a07a-957635e50ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Final model\n",
    "\n",
    "# Load model using the t5 small model\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# Establish the training arguments\n",
    "# Three epochs since this is the final model\n",
    "training_args = TrainingArguments(output_dir = './t5-final-model', \n",
    "                                  num_train_epochs = 3, \n",
    "                                  per_device_train_batch_size = 16, \n",
    "                                  per_device_eval_batch_size = 16, \n",
    "                                  warmup_steps = 10, \n",
    "                                  weight_decay = 0.01, \n",
    "                                  logging_dir = './logs', \n",
    "                                  logging_steps = 20, \n",
    "                                  save_total_limit = 1, \n",
    "                                  save_strategy = 'epoch', \n",
    "                                  evaluation_strategy = 'epoch', \n",
    "                                  fp16 = False)\n",
    "\n",
    "# Apply the training arguments, following ref in report doc, as well as \n",
    "# similarities to HW3\n",
    "trainer_t5 = Trainer(model = model_t5, \n",
    "                  args = training_args, \n",
    "                  train_dataset = t5_tokenized_datasets['train'], \n",
    "                  eval_dataset = t5_tokenized_datasets['validation'])\n",
    "\n",
    "trainer_t5.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635789d-a9e9-4a69-9ce0-078fcca18e42",
   "metadata": {},
   "source": [
    "## Evaluate the Final T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8a14c-b906-4515-981d-45ef53c34601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model to cpu for faster prediction\n",
    "model_t5 = model_t5.to('cpu')\n",
    "\n",
    "# Initialize empty list for the predictions and true_y\n",
    "predictions = []\n",
    "true_y = []\n",
    "\n",
    "# Loop through each item in the test dataset\n",
    "## Uses ref from report doc\n",
    "for row in t5_tokenized_datasets['test']:\n",
    "    # Tokenize the input text\n",
    "    input_tokenized = tokenizer_t5(row['input_text'], return_tensors = \"pt\", truncation = True, padding = True).input_ids\n",
    "    \n",
    "    # Generate the models generated text based on the input text\n",
    "    output_tokenized = model_t5.generate(input_tokenized, max_length = 128)[0]\n",
    "\n",
    "    # Decode the generated response to a string\n",
    "    pred = tokenizer_t5.decode(output_tokenized, skip_special_tokens = True)\n",
    "\n",
    "    # Get the corresponding true value for the current row\n",
    "    y = row['target_text']\n",
    "\n",
    "    # Add the generated prediction and true value to the lists\n",
    "    predictions.append(pred)\n",
    "    true_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd390a-2112-4454-babe-bceddd5c4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the BLEU score given the predicitons and true values\n",
    "bleu_score = bleu.compute(predictions = predictions, references = [[y] for y in true_y])\n",
    "\n",
    "# Compute the Rouge scores given the predictions and true values\n",
    "rouge_score = rouge.compute(predictions = predictions, references = true_y)\n",
    "\n",
    "# Print out the BLEU and Rogue scores\n",
    "print(\"BLEU:\", bleu_score['bleu'])\n",
    "print(\"ROUGE-1:\", rouge_score['rouge1'])\n",
    "print(\"ROUGE-2:\", rouge_score['rouge2'])\n",
    "print(\"ROUGE-L:\", rouge_score['rougeL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a816c8f-4b95-4598-8f3c-ef8a9424742d",
   "metadata": {},
   "source": [
    "## Tokenize Data for BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bec73-c9e7-47f7-b621-146cbb6492dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estabish an encoder to change the outcome labels to multi class label numbers\n",
    "# Uses ref from report doc as well as stackoverflow\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(bert_train['outcome_label'])\n",
    "\n",
    "# Apply the encoder to each split of the data so instead of text labels\n",
    "# each text label now corresponds to a number for that class\n",
    "bert_train['label'] = encoder.transform(bert_train['outcome_label'])\n",
    "bert_val['label'] = encoder.transform(bert_val['outcome_label'])\n",
    "bert_test1['label'] = encoder.transform(bert_test1['outcome_label'])\n",
    "bert_test2['label'] = encoder.transform(bert_test2['outcome_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52036d7-ad36-4c40-828e-a85c122aa7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the data into a dataset object dict \n",
    "# this is the format needed for training recommended by ref in report doc\n",
    "bert_dataset = DatasetDict({\"train\": Dataset.from_pandas(bert_train), \n",
    "                            \"val\": Dataset.from_pandas(bert_val), \n",
    "                            \"test\": Dataset.from_pandas(bert_test1)})\n",
    "\n",
    "# Initialize the tokenizer, same tokenizer from one of the homeworks\n",
    "# or from previous class, that's why it was chosen\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to tokenize the dataset for each row within it\n",
    "# Establoshed using ref from the report doc\n",
    "def tokenize(row):\n",
    "    return tokenizer_bert(row['target_text'], truncation = True, padding = \"max_length\", max_length = 128)\n",
    "\n",
    "# Map the tokenize function for each row within the dataset\n",
    "# So this tokenizes all of the data: train, val, and test1\n",
    "tokenized = bert_dataset.map(tokenize, batched = True)\n",
    "\n",
    "# Ensure that the dataset is in the proper format for training\n",
    "# Established with helpf from ref in report doc\n",
    "tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeaa92a-b310-4626-9045-49ae727331a7",
   "metadata": {},
   "source": [
    "## Tune for BERT Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8d37c-d9bd-445d-9e07-50f0ec85681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuning for weight decay larger = 0.01\n",
    "\n",
    "# Initialize the model from the pre trained model corresponding to the tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=8)  \n",
    "\n",
    "# Function to compute the F1 and accuracy for training and for evaluating later\n",
    "# Described from previous homeworks, and used from other courses\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average = 'macro') \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "# Establish the training arguments\n",
    "# Train one epoch because it is just fine tuning hyper parameters\n",
    "training_args = TrainingArguments(output_dir = \"./BERT-wd-0.01\",\n",
    "                                  num_train_epochs = 1, \n",
    "                                  per_device_train_batch_size = 16, \n",
    "                                  per_device_eval_batch_size = 16,\n",
    "                                  warmup_steps = 500,\n",
    "                                  weight_decay = 0.01, \n",
    "                                  logging_dir = \"./logs\",\n",
    "                                  logging_steps = 100)\n",
    "\n",
    "# Apply the training arguments, following ref in report doc, as well as \n",
    "# similarities to HW3\n",
    "trainer = Trainer(model = model, \n",
    "                  args = training_args, \n",
    "                  train_dataset = tokenized[\"train\"], \n",
    "                  eval_dataset = tokenized[\"val\"], \n",
    "                  compute_metrics = compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "# Get the results and print them for the F1 and accuracy\n",
    "eval_results = trainer.evaluate(tokenized[\"test\"])\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f82a8-3d56-4d3a-b077-ad72d0db67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuning for weight decay smaller = 0.0001\n",
    "\n",
    "# Initialize the model from the pre trained model corresponding to the tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=8)  \n",
    "\n",
    "# Function to compute the F1 and accuracy for training and for evaluating later\n",
    "# Described from previous homeworks, and used from other courses\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average = 'macro') \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "# Establish the training arguments\n",
    "# Train one epoch because it is just fine tuning hyper parameters\n",
    "training_args = TrainingArguments(output_dir = \"./BERT-wd-0.0001\",\n",
    "                                  num_train_epochs = 1, \n",
    "                                  per_device_train_batch_size = 16, \n",
    "                                  per_device_eval_batch_size = 16,\n",
    "                                  warmup_steps = 500,\n",
    "                                  weight_decay = 0.0001, \n",
    "                                  logging_dir = \"./logs\",\n",
    "                                  logging_steps = 100)\n",
    "\n",
    "# Apply the training arguments, following ref in report doc, as well as \n",
    "# similarities to HW3\n",
    "trainer = Trainer(model = model, \n",
    "                  args = training_args, \n",
    "                  train_dataset = tokenized[\"train\"], \n",
    "                  eval_dataset = tokenized[\"val\"], \n",
    "                  compute_metrics = compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "# Get the results and print them for the F1 and accuracy\n",
    "eval_results = trainer.evaluate(tokenized[\"test\"])\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e3538-8cc0-4511-97d1-68e8f73ccf16",
   "metadata": {},
   "source": [
    "## Train Final BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e663fe4-005d-4960-8f76-fcfe548add57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training final BERT model\n",
    "\n",
    "# Initialize the model from the pre trained model corresponding to the tokenizer\n",
    "model_bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=8)  \n",
    "\n",
    "# Function to compute the F1 and accuracy for training and for evaluating later\n",
    "# Described from previous homeworks, and used from other courses\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average = 'macro') \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "# Establish the training arguments\n",
    "# Train three epochs because final model\n",
    "training_args = TrainingArguments(output_dir = \"./BERT-final-model\",\n",
    "                                  num_train_epochs = 3, \n",
    "                                  per_device_train_batch_size = 16, \n",
    "                                  per_device_eval_batch_size = 16,\n",
    "                                  warmup_steps = 500,\n",
    "                                  weight_decay = 0.01, \n",
    "                                  logging_dir = \"./logs\",\n",
    "                                  logging_steps = 100)\n",
    "\n",
    "# Apply the training arguments, following ref in report doc, as well as \n",
    "# similarities to HW3\n",
    "trainer_bert = Trainer(model = model_bert, \n",
    "                  args = training_args, \n",
    "                  train_dataset = tokenized[\"train\"], \n",
    "                  eval_dataset = tokenized[\"val\"], \n",
    "                  compute_metrics = compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dec0e9-196e-41d1-8025-53a2495d06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_bert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df004bb-e6f1-46f5-bf37-27726eeec5f0",
   "metadata": {},
   "source": [
    "## Evaluate the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae351bf5-721d-4ae9-8f52-88c7c9a17da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results and print them for the F1 and accuracy\n",
    "eval_results = trainer_bert.evaluate(tokenized[\"test\"])\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2f905-d042-4e40-ba1b-39c6b12efd1d",
   "metadata": {},
   "source": [
    "## Evaluate the T5 Model Using the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d51d7-8352-4009-ace0-22e8de4320b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer using pretrained t5 small\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Convert dfs to datasets since the tokenizer needs them like this\n",
    "t5_set = Dataset.from_pandas(bert_test2[['input_text', 'target_text']])\n",
    "\n",
    "# Function to tokenize the data followind ref in report doc \n",
    "def tokenize(data_set):\n",
    "    # Tokenize the input text\n",
    "    input_enc = tokenizer_t5(data_set['input_text'], max_length = 512, padding = 'max_length', truncation = True)\n",
    "\n",
    "    # Tokenize the target text\n",
    "    target_enc = tokenizer_t5(data_set['target_text'], max_length = 128, padding = 'max_length', truncation = True)\n",
    "\n",
    "    # Place these in a dict format\n",
    "    return {'input_ids': input_enc.input_ids, 'attention_mask': input_enc.attention_mask, 'labels': target_enc.input_ids}\n",
    "\n",
    "# Final dataset dict\n",
    "t5_tokenized_set = {'test2': t5_set}\n",
    "\n",
    "# Tokenize all splits\n",
    "t5_tokenized_datasets_test2 = {split: data_set.map(tokenize, batched = False) for split, data_set in t5_tokenized_set.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d313b71-fdc6-4d10-bf14-69b56a4057e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model to cpu for faster prediction\n",
    "model_t5 = model_t5.to('cpu')\n",
    "\n",
    "# Initialize empty list for the predictions\n",
    "target_text = []\n",
    "\n",
    "# Loop through each item in the test dataset\n",
    "## Uses ref from report doc\n",
    "for row in t5_tokenized_datasets_test2['test2']:\n",
    "    # Tokenize the input text\n",
    "    input_tokenized = tokenizer_t5(row['input_text'], return_tensors = \"pt\", truncation = True, padding = True).input_ids\n",
    "    \n",
    "    # Generate the models generated text based on the input text\n",
    "    output_tokenized = model_t5.generate(input_tokenized, max_length = 128)[0]\n",
    "\n",
    "    # Decode the generated response to a string\n",
    "    pred = tokenizer_t5.decode(output_tokenized, skip_special_tokens = True)\n",
    "\n",
    "    # Get the corresponding true value for the current row\n",
    "    y = row['target_text']\n",
    "\n",
    "    # Add the generated prediction and true value to the lists\n",
    "    target_text.append(pred)\n",
    "\n",
    "bert_test2['target_text'] = target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28995a-9e04-42ab-bf0d-51c0031c274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the data into a dataset object dict \n",
    "# this is the format needed for training recommended by ref in report doc\n",
    "bert_dataset = DatasetDict({\"test2\": Dataset.from_pandas(bert_test2)})\n",
    "\n",
    "# Initialize the tokenizer, same tokenizer from one of the homeworks\n",
    "# or from previous class, that's why it was chosen\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to tokenize the dataset for each row within it\n",
    "# Establoshed using ref from the report doc\n",
    "def tokenize(row):\n",
    "    return tokenizer_bert(row['target_text'], truncation = True, padding = \"max_length\", max_length = 128)\n",
    "\n",
    "# Map the tokenize function for each row within the dataset\n",
    "# So this tokenizes all of the data: train, val, and test1\n",
    "tokenized = bert_dataset.map(tokenize, batched = True)\n",
    "\n",
    "# Ensure that the dataset is in the proper format for training\n",
    "# Established with helpf from ref in report doc\n",
    "tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc528468-5fb0-4d7d-96c9-f1c9e302676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results and print them for the F1 and accuracy\n",
    "eval_results = trainer_bert.evaluate(tokenized[\"test2\"])\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6350a6-be4d-41b9-82c3-249e009226b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
